{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrimeurVision - Fine-tuning YOLOv8\n",
    "\n",
    "Fine-tuning d'un modele **YOLOv8n pre-entraine sur COCO** pour detecter nos 6 classes de fruits/legumes.\n",
    "\n",
    "**Entrainement en 2 phases :**\n",
    "1. **Backbone gele** : on entraine uniquement la tete de detection\n",
    "2. **Fine-tuning complet** : on degele tout et on affine avec un learning rate plus faible\n",
    "\n",
    "**Classes** : carotte, aubergine, citron, pomme_de_terre, radis, tomate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation des dependances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HYPERPARAMETRES ---\n",
    "\n",
    "# Phase 1 : backbone gele\n",
    "PHASE1_EPOCHS = 10\n",
    "PHASE1_LR = 1e-2\n",
    "FREEZE_LAYERS = 10\n",
    "\n",
    "# Phase 2 : fine-tuning complet\n",
    "PHASE2_EPOCHS = 40\n",
    "PHASE2_LR = 1e-3\n",
    "\n",
    "# Parametres communs\n",
    "IMG_SIZE = 640\n",
    "BATCH_SIZE = 16\n",
    "PATIENCE = 10\n",
    "CONF_THRESHOLD = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Montage Google Drive et chargement du dataset\n",
    "\n",
    "Uploadez le dossier `dataset/` sur Google Drive dans `My Drive/PrimeurVision/dataset/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATASET_SRC = '/content/drive/MyDrive/PrimeurVision/dataset'\n",
    "WORK_DIR = '/content/dataset'\n",
    "\n",
    "# Copie en local pour accelerer l'entrainement\n",
    "if os.path.exists(WORK_DIR):\n",
    "    shutil.rmtree(WORK_DIR)\n",
    "shutil.copytree(DATASET_SRC, WORK_DIR)\n",
    "\n",
    "# Charger la config du dataset\n",
    "data_yaml_path = os.path.join(WORK_DIR, 'data.yaml')\n",
    "with open(data_yaml_path, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "CLASS_NAMES = data_config['names']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "print(f\"{NUM_CLASSES} classes : {CLASS_NAMES}\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_dir = os.path.join(WORK_DIR, 'images', split)\n",
    "    if os.path.exists(img_dir):\n",
    "        print(f\"  {split}: {len(os.listdir(img_dir))} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploration du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Affiche 6 images aléatoires avec leurs bounding boxes pour vérifier visuellement que les annotations sont correctes, puis montre la distribution des classes (combien de boxes par classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['#FF8C00', '#9B59B6', '#FFD700', '#8B4513', '#E74C3C', '#FF4444']\n",
    "\n",
    "def parse_yolo_label(label_path):\n",
    "    \"\"\"Lit un fichier label YOLO.\"\"\"\n",
    "    annotations = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                class_id = int(parts[0])\n",
    "                x_center, y_center, width, height = map(float, parts[1:])\n",
    "                annotations.append((class_id, x_center, y_center, width, height))\n",
    "    return annotations\n",
    "\n",
    "def plot_image_with_boxes(img_path, label_path, ax):\n",
    "    \"\"\"Affiche une image avec ses bounding boxes.\"\"\"\n",
    "    img = Image.open(img_path)\n",
    "    w, h = img.size\n",
    "    ax.imshow(img)\n",
    "\n",
    "    for class_id, xc, yc, bw, bh in parse_yolo_label(label_path):\n",
    "        x1 = (xc - bw / 2) * w\n",
    "        y1 = (yc - bh / 2) * h\n",
    "        color = COLORS[class_id % len(COLORS)]\n",
    "        rect = patches.Rectangle((x1, y1), bw * w, bh * h,\n",
    "                                 linewidth=2, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x1, y1 - 5, CLASS_NAMES.get(class_id, '?'), color=color,\n",
    "                fontsize=10, fontweight='bold', backgroundcolor='black')\n",
    "    ax.axis('off')\n",
    "\n",
    "# Afficher 6 images aleatoires du train\n",
    "train_images_dir = os.path.join(WORK_DIR, 'images', 'train')\n",
    "train_labels_dir = os.path.join(WORK_DIR, 'labels', 'train')\n",
    "\n",
    "image_files = sorted(glob.glob(os.path.join(train_images_dir, '*.jpg')))\n",
    "sample_images = random.sample(image_files, min(6, len(image_files)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for ax, img_path in zip(axes.flatten(), sample_images):\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    label_path = os.path.join(train_labels_dir, base_name + '.txt')\n",
    "    if os.path.exists(label_path):\n",
    "        plot_image_with_boxes(img_path, label_path, ax)\n",
    "\n",
    "plt.suptitle('Echantillon du dataset', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution des classes\n",
    "for split in ['train', 'val', 'test']:\n",
    "    labels_dir = os.path.join(WORK_DIR, 'labels', split)\n",
    "    if not os.path.exists(labels_dir):\n",
    "        continue\n",
    "    class_counts = {}\n",
    "    for lf in glob.glob(os.path.join(labels_dir, '*.txt')):\n",
    "        for class_id, *_ in parse_yolo_label(lf):\n",
    "            name = CLASS_NAMES.get(class_id, f'class_{class_id}')\n",
    "            class_counts[name] = class_counts.get(name, 0) + 1\n",
    "    print(f\"[{split}] {class_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mise a jour de data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met à jour les chemins dans le fichier de config pour qu'ils pointent vers le dataset local sur Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config['path'] = WORK_DIR\n",
    "data_config['train'] = 'images/train'\n",
    "data_config['val'] = 'images/val'\n",
    "data_config['test'] = 'images/test'\n",
    "\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    yaml.dump(data_config, f, default_flow_style=False)\n",
    "\n",
    "print(open(data_yaml_path).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Entrainement en 2 phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement phase 1 — Charge YOLOv8n pré-entraîné et l'entraîne avec le backbone gelé (seule la tête de détection apprend). Ça permet d'adapter le modèle à nos classes sans casser les features déjà apprises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement phase 2 — Reprend le meilleur modèle de la phase 1 et dégèle tout pour affiner l'ensemble du réseau avec un learning rate plus faible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 : backbone gele\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results_phase1 = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=PHASE1_EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    lr0=PHASE1_LR,\n",
    "    freeze=FREEZE_LAYERS,\n",
    "    name='primeurvision_phase1',\n",
    "    patience=PATIENCE,\n",
    "    save=True,\n",
    "    plots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 : fine-tuning complet a partir du meilleur modele phase 1\n",
    "best_phase1 = os.path.join('runs', 'detect', 'primeurvision_phase1', 'weights', 'best.pt')\n",
    "model = YOLO(best_phase1)\n",
    "\n",
    "results_phase2 = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=PHASE2_EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    lr0=PHASE2_LR,\n",
    "    freeze=0,\n",
    "    name='primeurvision_phase2',\n",
    "    patience=PATIENCE,\n",
    "    save=True,\n",
    "    plots=True\n",
    ")\n",
    "\n",
    "RESULTS_DIR = os.path.join('runs', 'detect', 'primeurvision_phase2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcule les métriques (mAP, précision, recall) sur la validation et le test, puis affiche l'AP par classe. Affiche les graphiques générés automatiquement par Ultralytics pendant l'entraînement (loss, mAP au fil des epochs, matrice de confusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation sur validation et test\n",
    "metrics_val = model.val()\n",
    "metrics_test = model.val(split='test')\n",
    "\n",
    "print(\"mAP@50  mAP@50-95  Precision  Recall\")\n",
    "print(f\"  Val  : {metrics_val.box.map50:.4f}  {metrics_val.box.map:.4f}     {metrics_val.box.mp:.4f}     {metrics_val.box.mr:.4f}\")\n",
    "print(f\"  Test : {metrics_test.box.map50:.4f}  {metrics_test.box.map:.4f}     {metrics_test.box.mp:.4f}     {metrics_test.box.mr:.4f}\")\n",
    "\n",
    "# AP@50 par classe (test)\n",
    "print(\"\\nAP@50 par classe (test) :\")\n",
    "for i, class_name in CLASS_NAMES.items():\n",
    "    ap50 = metrics_test.box.ap50[i] if i < len(metrics_test.box.ap50) else 0\n",
    "    print(f\"  {class_name:20s} : {ap50:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes d'entrainement\n",
    "results_img = os.path.join(RESULTS_DIR, 'results.png')\n",
    "if os.path.exists(results_img):\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.imshow(Image.open(results_img))\n",
    "    plt.axis('off')\n",
    "    plt.title('Courbes d\\'entrainement (phase 2)')\n",
    "    plt.show()\n",
    "\n",
    "# Matrice de confusion\n",
    "confusion_img = os.path.join(RESULTS_DIR, 'confusion_matrix.png')\n",
    "if os.path.exists(confusion_img):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(Image.open(confusion_img))\n",
    "    plt.axis('off')\n",
    "    plt.title('Matrice de confusion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predictions sur le test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fait tourner le modèle final sur 6 images de test et affiche les résultats visuellement avec les boxes prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = YOLO(os.path.join(RESULTS_DIR, 'weights', 'best.pt'))\n",
    "\n",
    "test_images = glob.glob(os.path.join(WORK_DIR, 'images', 'test', '*.jpg'))\n",
    "sample_test = random.sample(test_images, min(6, len(test_images)))\n",
    "\n",
    "n_cols = min(3, len(sample_test))\n",
    "n_rows = (len(sample_test) + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 6 * n_rows))\n",
    "if len(sample_test) == 1:\n",
    "    axes = [axes]\n",
    "else:\n",
    "    axes = axes.flatten()\n",
    "\n",
    "for ax, img_path in zip(axes, sample_test):\n",
    "    result = best_model.predict(img_path, conf=CONF_THRESHOLD, verbose=False)[0]\n",
    "    ax.imshow(result.plot()[:, :, ::-1])\n",
    "    ax.set_title(os.path.basename(img_path), fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "for i in range(len(sample_test), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Predictions sur le test', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sauvegarde du modele sur Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copie le meilleur modèle (best.pt) sur Google Drive pour pouvoir le réutiliser plus tard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/content/drive/MyDrive/PrimeurVision/models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "best_model_path = os.path.join(RESULTS_DIR, 'weights', 'best.pt')\n",
    "shutil.copy2(best_model_path, os.path.join(save_dir, 'best_yolov8n_primeurvision.pt'))\n",
    "\n",
    "print(f\"Modele sauvegarde : {save_dir}/best_yolov8n_primeurvision.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
