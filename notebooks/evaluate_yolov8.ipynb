{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eval-0",
   "metadata": {},
   "source": [
    "# PrimeurVision ‚Äî √âvaluation du mod√®le YOLOv8\n",
    "\n",
    "√âvaluation du **mod√®le final retenu** sur le **jeu de test** (36 images, jamais vues pendant l'entra√Ænement).\n",
    "\n",
    "**Mod√®le** : YOLOv8n (v1) ‚Äî meilleure g√©n√©ralisation malgr√© une capacit√© moindre que YOLOv8s (v2 trop grand pour 166 images d'entra√Ænement ‚Üí overfitting)\n",
    "\n",
    "**M√©triques** : mAP@50, mAP@50-95, Pr√©cision, Recall, AP par classe\n",
    "\n",
    "**Classes** : carotte (0), aubergine (1), citron (2), pomme_de_terre (3), radis (4), tomate (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-1",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eval-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-3",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eval-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-5",
   "metadata": {},
   "source": [
    "## 3. Chargement du mod√®le et du dataset\n",
    "\n",
    "**Colab** : charge depuis Google Drive.  \n",
    "**Local** : charge depuis `models/best_yolov8n_primeurvision.pt` dans le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eval-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racine projet : /Users/eugenie/Desktop/M2-SISE/13 - Deep learning - Machine learning - Computer Vision/projet_computer_vision\n",
      "Mod√®le        : /Users/eugenie/Desktop/M2-SISE/13 - Deep learning - Machine learning - Computer Vision/projet_computer_vision/models/best_yolov8n_primeurvision.pt\n",
      "Mod√®le existe : True\n",
      "Classes : ['carotte', 'aubergine', 'citron', 'pomme_de_terre', 'radis', 'tomate']\n",
      "Images de test : 36\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "ON_COLAB = 'google.colab' in sys.modules or 'google.colab' in str(sys.path)\n",
    "\n",
    "if ON_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Mod√®le final retenu : v1 (YOLOv8n)\n",
    "    MODEL_PATH  = '/content/drive/MyDrive/PrimeurVision/models/best_yolov8n_primeurvision.pt'\n",
    "    DATASET_SRC = '/content/drive/MyDrive/PrimeurVision/dataset'\n",
    "    MODELS_DIR  = '/content/drive/MyDrive/PrimeurVision/models'\n",
    "    WORK_DIR    = '/content/dataset'\n",
    "    if os.path.exists(WORK_DIR):\n",
    "        shutil.rmtree(WORK_DIR)\n",
    "    shutil.copytree(DATASET_SRC, WORK_DIR)\n",
    "else:\n",
    "    cwd = pathlib.Path(os.getcwd())\n",
    "    PROJECT_ROOT = None\n",
    "    for candidate in [cwd, cwd.parent]:\n",
    "        if (candidate / 'dataset' / 'data.yaml').exists():\n",
    "            PROJECT_ROOT = candidate\n",
    "            break\n",
    "    if PROJECT_ROOT is None:\n",
    "        raise FileNotFoundError(\"Impossible de trouver la racine du projet.\")\n",
    "\n",
    "    WORK_DIR   = str(PROJECT_ROOT / 'dataset')\n",
    "    MODELS_DIR = str(PROJECT_ROOT / 'models')\n",
    "    # Mod√®le final retenu : v1 (YOLOv8n) ‚Äî meilleure g√©n√©ralisation\n",
    "    MODEL_PATH = str(PROJECT_ROOT / 'models' / 'best_yolov8n_primeurvision.pt')\n",
    "    print(f\"Racine projet : {PROJECT_ROOT}\")\n",
    "    print(f\"Mod√®le        : {MODEL_PATH}\")\n",
    "    print(f\"Mod√®le existe : {os.path.exists(MODEL_PATH)}\")\n",
    "\n",
    "CONF_THRESHOLD = 0.25\n",
    "\n",
    "data_yaml_path = os.path.join(WORK_DIR, 'data.yaml')\n",
    "with open(data_yaml_path, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "data_config['path']  = WORK_DIR\n",
    "data_config['train'] = 'images/train'\n",
    "data_config['val']   = 'images/val'\n",
    "data_config['test']  = 'images/test'\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    yaml.dump(data_config, f, default_flow_style=False)\n",
    "\n",
    "CLASS_NAMES = data_config['names']\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(f\"Classes : {list(CLASS_NAMES.values())}\")\n",
    "print(f\"Images de test : {len(os.listdir(os.path.join(WORK_DIR, 'images', 'test')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-7",
   "metadata": {},
   "source": [
    "## 4. √âvaluation quantitative sur le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eval-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.14 üöÄ Python-3.11.14 torch-2.10.0 CPU (Apple M3)\n",
      "Model summary (fused): 73 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 345.6¬±477.1 MB/s, size: 89.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/eugenie/Desktop/M2-SISE/13 - Deep learning - Machine learning - Computer Vision/projet_computer_vision/dataset/labels/test.cache... 36 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 36/36 18.9Mit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 1.4s/it 4.3s3.7ss\n",
      "                   all         36        482      0.502      0.431      0.455      0.311\n",
      "               carotte          8        232      0.457      0.228       0.33      0.184\n",
      "             aubergine          7         30      0.643        0.3      0.482      0.328\n",
      "                citron          9         49      0.444      0.653      0.532      0.366\n",
      "        pomme_de_terre          8         54       0.72      0.667      0.695      0.512\n",
      "                 radis          8         59      0.412      0.119      0.281      0.179\n",
      "                tomate          8         58      0.333      0.621      0.411      0.299\n",
      "Speed: 0.4ms preprocess, 85.1ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/eugenie/Desktop/M2-SISE/13 - Deep learning - Machine learning - Computer Vision/projet_computer_vision/notebooks/runs/detect/val14\u001b[0m\n",
      "=============================================\n",
      "  R√âSULTATS SUR LE JEU DE TEST\n",
      "=============================================\n",
      "  mAP@50    : 0.4552\n",
      "  mAP@50-95 : 0.3112\n",
      "  Pr√©cision : 0.5015\n",
      "  Recall    : 0.4313\n",
      "---------------------------------------------\n",
      "  AP@50 par classe :\n",
      "  carotte              : 0.3301  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  aubergine            : 0.4823  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  citron               : 0.5321  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  pomme_de_terre       : 0.6951  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  radis                : 0.2806  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  tomate               : 0.4109  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=data_yaml_path, split='test', conf=CONF_THRESHOLD)\n",
    "\n",
    "print(\"=\" * 45)\n",
    "print(\"  R√âSULTATS SUR LE JEU DE TEST\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"  mAP@50    : {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95 : {metrics.box.map:.4f}\")\n",
    "print(f\"  Pr√©cision : {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall    : {metrics.box.mr:.4f}\")\n",
    "print(\"-\" * 45)\n",
    "print(\"  AP@50 par classe :\")\n",
    "for i, name in CLASS_NAMES.items():\n",
    "    ap50 = metrics.box.ap50[i] if i < len(metrics.box.ap50) else 0\n",
    "    bar  = '‚ñà' * int(ap50 * 20)\n",
    "    print(f\"  {name:20s} : {ap50:.4f}  {bar}\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-9",
   "metadata": {},
   "source": [
    "## 5. Matrice de confusion et courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eval-10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dir = str(metrics.save_dir)\n",
    "\n",
    "# Matrice de confusion normalis√©e\n",
    "for fname in ['confusion_matrix_normalized.png', 'confusion_matrix.png']:\n",
    "    confusion_img = os.path.join(eval_dir, fname)\n",
    "    if os.path.exists(confusion_img):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(Image.open(confusion_img))\n",
    "        plt.axis('off')\n",
    "        plt.title('Matrice de confusion ‚Äî jeu de test')\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "# Courbe Pr√©cision-Rappel\n",
    "pr_img = os.path.join(eval_dir, 'PR_curve.png')\n",
    "if os.path.exists(pr_img):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(Image.open(pr_img))\n",
    "    plt.axis('off')\n",
    "    plt.title('Courbe Pr√©cision-Rappel ‚Äî jeu de test')\n",
    "    plt.show()\n",
    "\n",
    "# Courbes d'entra√Ænement (depuis dossier models/)\n",
    "curves_img = os.path.join(MODELS_DIR, 'results.png')\n",
    "if os.path.exists(curves_img):\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.imshow(Image.open(curves_img))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Courbes d'entra√Ænement (phase 2)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"(courbes d'entra√Ænement non trouv√©es dans {MODELS_DIR})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-11",
   "metadata": {},
   "source": [
    "## 6. R√©sultats qualitatifs ‚Äî Pr√©dictions r√©ussies\n",
    "\n",
    "Exemples de d√©tections correctes sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eval-12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_images = glob.glob(os.path.join(WORK_DIR, 'images', 'test', '*.jpg'))\n",
    "\n",
    "def load_gt_classes(img_path):\n",
    "    \"\"\"Charge les classes ground truth depuis le fichier label YOLO.\"\"\"\n",
    "    label_path = img_path.replace('images', 'labels').replace('.jpg', '.txt')\n",
    "    if not os.path.exists(label_path):\n",
    "        return set()\n",
    "    with open(label_path) as f:\n",
    "        return set(int(line.split()[0]) for line in f if line.strip())\n",
    "\n",
    "def score_image(img_path, result):\n",
    "    \"\"\"\n",
    "    Score de r√©ussite : fraction des classes GT correctement pr√©dites.\n",
    "    Bonus si la confiance est √©lev√©e et pas de faux positifs.\n",
    "    \"\"\"\n",
    "    gt_classes   = load_gt_classes(img_path)\n",
    "    pred_classes = set(int(c) for c in result.boxes.cls) if len(result.boxes) > 0 else set()\n",
    "    if not gt_classes:\n",
    "        return 0.0\n",
    "    true_pos     = len(gt_classes & pred_classes)\n",
    "    false_pos    = len(pred_classes - gt_classes)\n",
    "    recall_score = true_pos / len(gt_classes)\n",
    "    penalty      = false_pos / max(len(pred_classes), 1)\n",
    "    avg_conf     = float(result.boxes.conf.mean()) if len(result.boxes) > 0 else 0.0\n",
    "    return recall_score * (1 - 0.3 * penalty) + 0.1 * avg_conf\n",
    "\n",
    "# √âvaluer toutes les images\n",
    "all_scored = []\n",
    "for img_path in test_images:\n",
    "    result = model.predict(img_path, conf=CONF_THRESHOLD, verbose=False)[0]\n",
    "    score  = score_image(img_path, result)\n",
    "    all_scored.append((img_path, result, score))\n",
    "\n",
    "# Trier du meilleur au moins bon\n",
    "all_scored.sort(key=lambda x: x[2], reverse=True)\n",
    "best = all_scored[:3]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for ax, (img_path, result, score) in zip(axes, best):\n",
    "    ax.imshow(result.plot()[:, :, ::-1])\n",
    "    gt = load_gt_classes(img_path)\n",
    "    ax.set_title(\n",
    "        f\"GT: {set(CLASS_NAMES[c] for c in gt)}  |  score: {score:.2f}\",\n",
    "        fontsize=11, color='green', fontweight='bold'\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Pr√©dictions les plus r√©ussies ‚Äî jeu de test', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROJECT_ROOT, 'docs', 'img', 'predictions_reussies.png'),\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-13",
   "metadata": {},
   "source": [
    "## 7. Analyse des erreurs ‚Äî Cas difficiles\n",
    "\n",
    "On identifie les images o√π le mod√®le d√©tecte peu ou avec une faible confiance. Ces cas r√©v√®lent les limites du mod√®le : objets partiellement visibles, occlusions, angles atypiques, ou classes sous-repr√©sent√©es dans le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eval-14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sans aucune d√©tection      : 1/36\n",
      "Images bien d√©tect√©es (score‚â•0.9) : 23/36\n"
     ]
    }
   ],
   "source": [
    "# all_scored est d√©j√† tri√© du meilleur au moins bon (calcul√© en cellule pr√©c√©dente)\n",
    "# On exclut les images sans GT (label vide) : leur score=0 ne refl√®te pas un √©chec de d√©tection\n",
    "scored_with_gt = [(p, r, s) for p, r, s in all_scored if load_gt_classes(p)]\n",
    "\n",
    "# Les cas difficiles = score le plus bas parmi les images annot√©es\n",
    "worst = scored_with_gt[-3:][::-1]  # 3 pires, du plus mauvais au moins mauvais\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for ax, (img_path, result, score) in zip(axes, worst):\n",
    "    ax.imshow(result.plot()[:, :, ::-1])\n",
    "    gt     = load_gt_classes(img_path)\n",
    "    pred   = set(int(c) for c in result.boxes.cls) if len(result.boxes) > 0 else set()\n",
    "    missed = gt - pred\n",
    "    ax.set_title(\n",
    "        f\"GT: {set(CLASS_NAMES[c] for c in gt)}\\n\"\n",
    "        f\"Manqu√©s: {set(CLASS_NAMES[c] for c in missed) if missed else chr(8709)}  |  score: {score:.2f}\",\n",
    "        fontsize=11, color='crimson', fontweight='bold'\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Cas difficiles ‚Äî pr√©dictions les plus √©loign√©es du ground truth', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PROJECT_ROOT, 'docs', 'img', 'predictions_difficiles.png'),\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# R√©sum√©\n",
    "n_zero = sum(1 for _, r, _ in all_scored if len(r.boxes) == 0)\n",
    "n_ok   = sum(1 for _, _, s in all_scored if s >= 0.9)\n",
    "print(f\"Images sans aucune d√©tection      : {n_zero}/{len(all_scored)}\")\n",
    "print(f\"Images bien d√©tect√©es (score‚â•0.9) : {n_ok}/{len(all_scored)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-15",
   "metadata": {},
   "source": [
    "## 8. Distribution des confiances et des classes d√©tect√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eval-16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d√©tections : 361\n",
      "Confiance moyenne : 0.522\n",
      "Confiance m√©diane : 0.482\n"
     ]
    }
   ],
   "source": [
    "COLORS = ['#FF8C00', '#9B59B6', '#FFD700', '#8B4513', '#E74C3C', '#FF4444']\n",
    "\n",
    "all_confs    = []\n",
    "class_counts = {v: 0 for v in CLASS_NAMES.values()}\n",
    "\n",
    "for img_path in test_images:\n",
    "    result = model.predict(img_path, conf=CONF_THRESHOLD, verbose=False)[0]\n",
    "    for box in result.boxes:\n",
    "        all_confs.append(float(box.conf))\n",
    "        name = CLASS_NAMES.get(int(box.cls), f'class_{int(box.cls)}')\n",
    "        class_counts[name] = class_counts.get(name, 0) + 1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution des scores de confiance\n",
    "ax1.hist(all_confs, bins=20, color='steelblue', edgecolor='white')\n",
    "ax1.axvline(CONF_THRESHOLD, color='red', linestyle='--', label=f'Seuil = {CONF_THRESHOLD}')\n",
    "ax1.set_title('Distribution des scores de confiance (test)')\n",
    "ax1.set_xlabel('Confiance')\n",
    "ax1.set_ylabel('Nombre de d√©tections')\n",
    "ax1.legend()\n",
    "\n",
    "# Nombre de d√©tections par classe pr√©dite\n",
    "bars = ax2.bar(class_counts.keys(), class_counts.values(), color=COLORS)\n",
    "ax2.bar_label(bars)\n",
    "ax2.set_title('D√©tections par classe (jeu de test)')\n",
    "ax2.set_xlabel('Classe')\n",
    "ax2.set_ylabel('Nb d√©tections')\n",
    "ax2.tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total d√©tections : {len(all_confs)}\")\n",
    "if all_confs:\n",
    "    print(f\"Confiance moyenne : {np.mean(all_confs):.3f}\")\n",
    "    print(f\"Confiance m√©diane : {np.median(all_confs):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primeurvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
