{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eval-0",
   "metadata": {},
   "source": [
    "# PrimeurVision ‚Äî √âvaluation du mod√®le YOLOv8\n",
    "\n",
    "√âvaluation du meilleur mod√®le issu de l'entra√Ænement sur le **jeu de test** (36 images, jamais vues pendant l'entra√Ænement).\n",
    "\n",
    "**M√©triques** : mAP@50, mAP@50-95, Pr√©cision, Recall, AP par classe\n",
    "\n",
    "**Classes** : carotte (0), aubergine (1), citron (2), pomme_de_terre (3), radis (4), tomate (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-1",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eval-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-3",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eval-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-5",
   "metadata": {},
   "source": [
    "## 3. Chargement du mod√®le et du dataset\n",
    "\n",
    "**Colab** : charge depuis Google Drive.  \n",
    "**Local** : charge depuis `models/best_yolov8n_primeurvision.pt` dans le projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-6",
   "metadata": {},
   "outputs": [],
   "source": "import sys\n\nON_COLAB = 'google.colab' in sys.modules or 'google.colab' in str(sys.path)\n\nif ON_COLAB:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    MODEL_PATH  = '/content/drive/MyDrive/PrimeurVision/models/best_yolov8s_primeurvision_v2.pt'\n    DATASET_SRC = '/content/drive/MyDrive/PrimeurVision/dataset'\n    MODELS_DIR  = '/content/drive/MyDrive/PrimeurVision/models'\n    WORK_DIR    = '/content/dataset'\n    if os.path.exists(WORK_DIR):\n        shutil.rmtree(WORK_DIR)\n    shutil.copytree(DATASET_SRC, WORK_DIR)\nelse:\n    PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n    WORK_DIR     = os.path.join(PROJECT_ROOT, 'dataset')\n    MODELS_DIR   = os.path.join(PROJECT_ROOT, 'models')\n    MODEL_PATH   = os.path.join(MODELS_DIR, 'best_yolov8s_primeurvision_v2.pt')\n    print(f\"Mode local ‚Äî dataset : {WORK_DIR}\")\n\nCONF_THRESHOLD = 0.25\n\n# Charger et mettre √† jour la config\ndata_yaml_path = os.path.join(WORK_DIR, 'data.yaml')\nwith open(data_yaml_path, 'r') as f:\n    data_config = yaml.safe_load(f)\n\ndata_config['path']  = WORK_DIR\ndata_config['train'] = 'images/train'\ndata_config['val']   = 'images/val'\ndata_config['test']  = 'images/test'\nwith open(data_yaml_path, 'w') as f:\n    yaml.dump(data_config, f, default_flow_style=False)\n\nCLASS_NAMES = data_config['names']\n\n# Charger le mod√®le\nmodel = YOLO(MODEL_PATH)\nprint(f\"Mod√®le charg√© : {MODEL_PATH}\")\nprint(f\"Classes : {list(CLASS_NAMES.values())}\")\nprint(f\"Images de test : {len(os.listdir(os.path.join(WORK_DIR, 'images', 'test')))}\")"
  },
  {
   "cell_type": "markdown",
   "id": "eval-7",
   "metadata": {},
   "source": [
    "## 4. √âvaluation quantitative sur le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eval-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.14 üöÄ Python-3.11.14 torch-2.10.0 CPU (Apple M3)\n",
      "Model summary (fused): 73 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1095.8¬±1329.7 MB/s, size: 1921.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/eugenie/Desktop/M2-SISE/13 - Deep learning - Machine learning - Computer Vision/projet_computer_vision/dataset/labels/test... 36 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 36/36 2.0Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/eugenie/Desktop/M2-SISE/13 - Deep learning - Machine learning - Computer Vision/projet_computer_vision/dataset/labels/test.cache\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 1.4s/it 4.3s3.8ss\n",
      "                   all         36        482      0.502      0.431      0.455      0.311\n",
      "               carotte          8        232      0.457      0.228       0.33      0.184\n",
      "             aubergine          7         30      0.643        0.3      0.482      0.328\n",
      "                citron          9         49      0.444      0.653      0.532      0.366\n",
      "        pomme_de_terre          8         54       0.72      0.667      0.695      0.512\n",
      "                 radis          8         59      0.412      0.119      0.281      0.179\n",
      "                tomate          8         58      0.333      0.621      0.411      0.299\n",
      "Speed: 0.4ms preprocess, 86.0ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/eugenie/Desktop/M2-SISE/13 - Deep learning - Machine learning - Computer Vision/projet_computer_vision/notebooks/runs/detect/val2\u001b[0m\n",
      "=============================================\n",
      "  R√âSULTATS SUR LE JEU DE TEST\n",
      "=============================================\n",
      "  mAP@50    : 0.4552\n",
      "  mAP@50-95 : 0.3112\n",
      "  Pr√©cision : 0.5015\n",
      "  Recall    : 0.4313\n",
      "---------------------------------------------\n",
      "  AP@50 par classe :\n",
      "  carotte              : 0.3301  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  aubergine            : 0.4823  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  citron               : 0.5321  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  pomme_de_terre       : 0.6951  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  radis                : 0.2806  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  tomate               : 0.4109  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(data=data_yaml_path, split='test', conf=CONF_THRESHOLD)\n",
    "\n",
    "print(\"=\" * 45)\n",
    "print(\"  R√âSULTATS SUR LE JEU DE TEST\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"  mAP@50    : {metrics.box.map50:.4f}\")\n",
    "print(f\"  mAP@50-95 : {metrics.box.map:.4f}\")\n",
    "print(f\"  Pr√©cision : {metrics.box.mp:.4f}\")\n",
    "print(f\"  Recall    : {metrics.box.mr:.4f}\")\n",
    "print(\"-\" * 45)\n",
    "print(\"  AP@50 par classe :\")\n",
    "for i, name in CLASS_NAMES.items():\n",
    "    ap50 = metrics.box.ap50[i] if i < len(metrics.box.ap50) else 0\n",
    "    bar  = '‚ñà' * int(ap50 * 20)\n",
    "    print(f\"  {name:20s} : {ap50:.4f}  {bar}\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-9",
   "metadata": {},
   "source": [
    "## 5. Matrice de confusion et courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eval-10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dir = str(metrics.save_dir)\n",
    "\n",
    "# Matrice de confusion normalis√©e\n",
    "for fname in ['confusion_matrix_normalized.png', 'confusion_matrix.png']:\n",
    "    confusion_img = os.path.join(eval_dir, fname)\n",
    "    if os.path.exists(confusion_img):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(Image.open(confusion_img))\n",
    "        plt.axis('off')\n",
    "        plt.title('Matrice de confusion ‚Äî jeu de test')\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "# Courbe Pr√©cision-Rappel\n",
    "pr_img = os.path.join(eval_dir, 'PR_curve.png')\n",
    "if os.path.exists(pr_img):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(Image.open(pr_img))\n",
    "    plt.axis('off')\n",
    "    plt.title('Courbe Pr√©cision-Rappel ‚Äî jeu de test')\n",
    "    plt.show()\n",
    "\n",
    "# Courbes d'entra√Ænement (depuis dossier models/)\n",
    "curves_img = os.path.join(MODELS_DIR, 'results.png')\n",
    "if os.path.exists(curves_img):\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.imshow(Image.open(curves_img))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Courbes d'entra√Ænement (phase 2)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"(courbes d'entra√Ænement non trouv√©es dans {MODELS_DIR})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-11",
   "metadata": {},
   "source": [
    "## 6. R√©sultats qualitatifs ‚Äî Pr√©dictions r√©ussies\n",
    "\n",
    "Exemples de d√©tections correctes sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eval-12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_images = glob.glob(os.path.join(WORK_DIR, 'images', 'test', '*.jpg'))\n",
    "sample_test = random.sample(test_images, min(6, len(test_images)))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "for ax, img_path in zip(axes.flatten(), sample_test):\n",
    "    result = model.predict(img_path, conf=CONF_THRESHOLD, verbose=False)[0]\n",
    "    ax.imshow(result.plot()[:, :, ::-1])\n",
    "    n_det = len(result.boxes)\n",
    "    ax.set_title(\n",
    "        f\"{os.path.basename(img_path)[:25]}\\n({n_det} d√©tection(s))\",\n",
    "        fontsize=8\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Exemples de pr√©dictions r√©ussies ‚Äî jeu de test', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-13",
   "metadata": {},
   "source": [
    "## 7. Analyse des erreurs ‚Äî Cas difficiles\n",
    "\n",
    "On identifie les images o√π le mod√®le d√©tecte peu ou avec une faible confiance. Ces cas r√©v√®lent les limites du mod√®le : objets partiellement visibles, occlusions, angles atypiques, ou classes sous-repr√©sent√©es dans le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eval-14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sans aucune d√©tection : 1/36\n",
      "Confiance moyenne (images avec d√©tections) : 0.769\n",
      "Confiance m√©diane : 0.820\n"
     ]
    }
   ],
   "source": [
    "# Collecter toutes les pr√©dictions sur le jeu de test\n",
    "all_results = []\n",
    "for img_path in test_images:\n",
    "    result   = model.predict(img_path, conf=CONF_THRESHOLD, verbose=False)[0]\n",
    "    n_det    = len(result.boxes)\n",
    "    max_conf = float(result.boxes.conf.max()) if n_det > 0 else 0.0\n",
    "    all_results.append((img_path, result, n_det, max_conf))\n",
    "\n",
    "# Trier par confiance maximale croissante (les cas les plus difficiles en premier)\n",
    "all_results.sort(key=lambda x: x[3])\n",
    "\n",
    "# Afficher les 6 images les plus probl√©matiques\n",
    "worst = all_results[:min(6, len(all_results))]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "for ax, (img_path, result, n_det, max_conf) in zip(axes.flatten(), worst):\n",
    "    ax.imshow(result.plot()[:, :, ::-1])\n",
    "    ax.set_title(\n",
    "        f\"{os.path.basename(img_path)[:25]}\\n\"\n",
    "        f\"{n_det} det. | conf max = {max_conf:.2f}\",\n",
    "        fontsize=8, color='crimson'\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Cas difficiles ‚Äî confiance maximale la plus faible', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# R√©sum√©\n",
    "n_zero = sum(1 for _, _, n, _ in all_results if n == 0)\n",
    "confs  = [c for _, _, n, c in all_results if n > 0]\n",
    "print(f\"Images sans aucune d√©tection : {n_zero}/{len(all_results)}\")\n",
    "if confs:\n",
    "    print(f\"Confiance moyenne (images avec d√©tections) : {np.mean(confs):.3f}\")\n",
    "    print(f\"Confiance m√©diane : {np.median(confs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-15",
   "metadata": {},
   "source": [
    "## 8. Distribution des confiances et des classes d√©tect√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eval-16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d√©tections : 361\n",
      "Confiance moyenne : 0.522\n",
      "Confiance m√©diane : 0.482\n"
     ]
    }
   ],
   "source": [
    "COLORS = ['#FF8C00', '#9B59B6', '#FFD700', '#8B4513', '#E74C3C', '#FF4444']\n",
    "\n",
    "all_confs    = []\n",
    "class_counts = {v: 0 for v in CLASS_NAMES.values()}\n",
    "\n",
    "for img_path in test_images:\n",
    "    result = model.predict(img_path, conf=CONF_THRESHOLD, verbose=False)[0]\n",
    "    for box in result.boxes:\n",
    "        all_confs.append(float(box.conf))\n",
    "        name = CLASS_NAMES.get(int(box.cls), f'class_{int(box.cls)}')\n",
    "        class_counts[name] = class_counts.get(name, 0) + 1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribution des scores de confiance\n",
    "ax1.hist(all_confs, bins=20, color='steelblue', edgecolor='white')\n",
    "ax1.axvline(CONF_THRESHOLD, color='red', linestyle='--', label=f'Seuil = {CONF_THRESHOLD}')\n",
    "ax1.set_title('Distribution des scores de confiance (test)')\n",
    "ax1.set_xlabel('Confiance')\n",
    "ax1.set_ylabel('Nombre de d√©tections')\n",
    "ax1.legend()\n",
    "\n",
    "# Nombre de d√©tections par classe pr√©dite\n",
    "bars = ax2.bar(class_counts.keys(), class_counts.values(), color=COLORS)\n",
    "ax2.bar_label(bars)\n",
    "ax2.set_title('D√©tections par classe (jeu de test)')\n",
    "ax2.set_xlabel('Classe')\n",
    "ax2.set_ylabel('Nb d√©tections')\n",
    "ax2.tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total d√©tections : {len(all_confs)}\")\n",
    "if all_confs:\n",
    "    print(f\"Confiance moyenne : {np.mean(all_confs):.3f}\")\n",
    "    print(f\"Confiance m√©diane : {np.median(all_confs):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "primeurvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}